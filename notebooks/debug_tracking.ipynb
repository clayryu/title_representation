{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MeasureNoteModel과 MeasureNumberSet을 사용하는 경우를 분석하려고 한다.\n",
    "# MeasureNumberSet은 get_item의 경우에 3가지 아웃풋을 내보낸다.\n",
    "# melody, shifted_melody, measure_numbers의 아웃풋 중에서 \n",
    "# melody와 measure_numbers만을 모델에 넣어주면 된다.\n",
    "# shifted_melody는 melody를 한 칸씩 shift한 것으로 모델의 pred와 비교해 loss를 구할때 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['main',\n",
       " 'dur',\n",
       " 'pitch_class',\n",
       " 'octave',\n",
       " 'm_idx',\n",
       " 'm_idx_mod4',\n",
       " 'm_offset',\n",
       " 'is_onbeat',\n",
       " 'is_middle_beat',\n",
       " 'key',\n",
       " 'meter',\n",
       " 'unit_length',\n",
       " 'rhythm',\n",
       " 'root',\n",
       " 'mode',\n",
       " 'key_sig',\n",
       " 'numer',\n",
       " 'denom',\n",
       " 'is_compound',\n",
       " 'is_triple']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer.py에서 batch를 받아서 model에 넣어주는 과정에서 3등분을 해준다.\n",
    "# melody, shifted_melody, measure_numbers = batch\n",
    "# collate_fn을 거쳐 각각은 packed sequence로 만들어진다.\n",
    "# 따라서 인풋은 token_size x input_size의 텐서로 변환된다.\n",
    "# MeasureNumberSet의 경우에는 input_size가 20이다.\n",
    "# 그 종류는 아래와 같다.\n",
    "['main', 'dur', 'pitch_class', 'octave', 'm_idx', 'm_idx_mod4', 'm_offset', 'is_onbeat', 'is_middle_beat',\n",
    " 'key', 'meter', 'unit_length', 'rhythm', 'root', 'mode', 'key_sig',  'numer', 'denom','is_compound', 'is_triple']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 구조에서 forward 부분을 살펴볼 필요가 있다.\n",
    "순서는 input_seq -> embedding layer -> rnn layer -> measure_rnn -> final_rnn -> projection(linear) layer로 이루어져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, input_seq, measure_numbers):\n",
    "    if isinstance(input_seq, PackedSequence):\n",
    "      emb = self._get_embedding(input_seq)\n",
    "      hidden, _ = self.rnn(emb)\n",
    "      measure_hidden = self.measure_rnn(hidden, measure_numbers)\n",
    "\n",
    "      cat_hidden = PackedSequence(torch.cat([hidden.data, measure_hidden.data], dim=-1), hidden.batch_sizes, hidden.sorted_indices, hidden.unsorted_indices)\n",
    "      \n",
    "      final_hidden, _ = self.final_rnn(cat_hidden)\n",
    "\n",
    "      logit = self.proj(final_hidden.data)\n",
    "      prob = self._apply_softmax(logit)\n",
    "      prob = PackedSequence(prob, input_seq[1], input_seq[2], input_seq[3])\n",
    "      return prob\n",
    "    else:\n",
    "      raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## embedding\n",
    "# model.emb에 들어가는 것은 input 중에서 melody이다.\n",
    "# data_sample = next(iter(train_loader))\n",
    "# emb = model._get_embedding(data_sample[0])\n",
    "# data_sample[0].data.shape\n",
    "# torch.Size([4820, 20])\n",
    "# emb.data.shape\n",
    "# torch.Size([4820, 2624])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rnn\n",
    "# rnn에서 헷갈리기 쉬운 것은 hidden과 last_hidden이다.\n",
    "# hidden은 token(sum of timestep of input sequence in every batch) x embedding_size(2624)를 token x hidden_size(512)로 변환해준다.\n",
    "# last_hidden은 마지막 token이 가질 모든 정보를 담고 있다. num_layers(3) x num_directions(1) x batch_size(32) x hidden_size(512)\n",
    "# hidden, last_hidden = model.rnn(emb)\n",
    "# hidden.data.shape\n",
    "# torch.Size([4820, 512])\n",
    "# last_hidden.data.shape\n",
    "# torch.Size([3, 32, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## measure_rnn\n",
    "# attention을 사용한다. 명확하게 이해하지는 못했다.\n",
    "# input 중에서 3번째인 measure_numbers를 함께 넣어준다.\n",
    "# measure_hidden = model.measure_rnn(hidden, data_sample[2])\n",
    "# measure_hidden.data.shape\n",
    "# torch.Size([4820, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## final_rnn\n",
    "# cat_hidden은 hidden과 measure_hidden의 data 부분을 concat한 것이다.\n",
    "# 이로써 각 토큰은 1024차원의 latent vector를 갖게 된다.\n",
    "# 이 latent vector를 final_rnn에 넣어준다.\n",
    "# final_hidden, last_final_hidden = model.final_rnn(cat_hidden)\n",
    "# final_hidden.data.shape\n",
    "# torch.Size([4820, 512])\n",
    "# last_final_hidden.data.shape\n",
    "# torch.Size([3, 32, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이후에 title embedding을 위해서는 각각의 tune에 맞는 embedding vector를 구해야한다.\n",
    "이를 위해서 나는 final_hidden을 학습하는 추가적인 rnn을 만들거나 attention을 구현해야 한다.\n",
    "우선은 bi-directional rnn을 사용해보려고 한다.\n",
    "rnn이 순차적으로 모든 token을 양방향으로 보고 hidden vector를 token x vector로  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
