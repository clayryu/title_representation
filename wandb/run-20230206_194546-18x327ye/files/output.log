
0.0004
  0%|                                                                                                                                                                                                                                                          | 0/9000 [00:00<?, ?it/s]
batch_time: 2.8995187282562256
get_batch_contrastive_loss time: 2.475299835205078
passed train_by_single_batch
An arbitrary loader is used instead of Validation loader

  0%|                                                                                                                                                                                                                                                             | 0/1 [00:00<?, ?it/s]
0.0004

  0%|                                                                                                                                                                                                                                               | 2/9000 [00:19<22:52:15,  9.15s/it]
get_batch_contrastive_loss time: 0.9792745113372803
passed train_by_single_batch
0.0004
batch_time: 2.829392194747925

  0%|                                                                                                                                                                                                                                               | 3/9000 [00:24<18:25:49,  7.37s/it]
passed train_by_single_batch
0.0004

  0%|                                                                                                                                                                                                                                               | 4/9000 [00:30<16:55:55,  6.78s/it]
get_batch_contrastive_loss time: 0.9786629676818848
passed train_by_single_batch
0.0004
  0%|                                                                                                                                                                                                                                               | 4/9000 [00:35<22:03:09,  8.82s/it]
Traceback (most recent call last):
  File "emb_train.py", line 167, in <module>
    trainer.train_by_num_epoch(args.num_epochs)
  File "/home/clay/userdata/title_generation/emb_trainer.py", line 89, in train_by_num_epoch
    loss_value, loss_dict = self._train_by_single_batch(batch, reg_abc_loss=None, reg_ttl_loss=None)
  File "/home/clay/userdata/title_generation/emb_trainer.py", line 153, in _train_by_single_batch
    loss, loss_dict = self.get_loss_pred_from_single_batch(batch)
  File "/home/clay/userdata/title_generation/emb_trainer.py", line 334, in get_loss_pred_from_single_batch
    loss = self.loss_fn(emb1, emb2)
  File "/home/clay/userdata/title_generation/emb_loss.py", line 13, in __call__
    return self.get_batch_contrastive_loss(emb1, emb2)
  File "/home/clay/userdata/title_generation/emb_loss.py", line 31, in get_batch_contrastive_loss
    negative_sim = cos_sim_value[non_diag_index].reshape(num_batch, num_batch-1)
KeyboardInterrupt