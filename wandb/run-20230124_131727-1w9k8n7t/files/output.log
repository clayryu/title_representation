
  0%|                                                                                                                                                                                                                                                   | 0/6000 [00:00<?, ?it/s]
0.001
An arbitrary loader is used instead of Validation loader

  0%|                                                                                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]
Saving the model with best validation loss: Epoch 1, Loss: 0.4000
0.001
  0%|                                                                                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]


  0%|                                                                                                                                                                                                                                        | 2/6000 [00:22<18:52:51, 11.33s/it]
Saving the model with best validation loss: Epoch 2, Loss: 0.4000
0.001
  0%|                                                                                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]

An arbitrary loader is used instead of Validation loader
Saving the model with best validation loss: Epoch 3, Loss: 0.4000
0.001
  0%|                                                                                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "emb_train.py", line 162, in <module>
    trainer.train_by_num_epoch(args.num_epochs)
  File "/home/clay/userdata/title_generation/emb_trainer.py", line 88, in train_by_num_epoch
    validation_loss, validation_acc = self.validate()
  File "/home/clay/userdata/title_generation/emb_trainer.py", line 388, in validate
    for idx, batch in enumerate(tqdm(loader, leave=False)):
  File "/usr/local/lib/python3.8/dist-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 290, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/clay/userdata/title_generation/emb_data_utils.py", line 515, in __getitem__
    tune_in_idx = [self.vocab(token, new_header) for token in tune]
  File "/home/clay/userdata/title_generation/emb_data_utils.py", line 515, in <listcomp>
    tune_in_idx = [self.vocab(token, new_header) for token in tune]
  File "/home/clay/userdata/title_generation/vocab_utils.py", line 354, in __call__
    if isinstance(word, list) and len(word) == 3: # token, measure_idx, measure_offset
KeyboardInterrupt