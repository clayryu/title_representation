
  0%|                                                                                                                                                                                                                                                           | 0/9000 [00:00<?, ?it/s]
0.0004
batch_time: 2.818711280822754
  0%|                                                                                                                                                                                                                                                              | 0/1 [00:00<?, ?it/s]
get_batch_contrastive_loss time: 2.4090218544006348
passed train_by_single_batch

An arbitrary loader is used instead of Validation loader
0.0004

  0%|                                                                                                                                                                                                                                                | 2/9000 [00:15<18:09:13,  7.26s/it]
get_batch_contrastive_loss time: 0.9703974723815918
passed train_by_single_batch

  0%|                                                                                                                                                                                                                                                | 3/9000 [00:19<14:17:36,  5.72s/it]
batch_time: 2.754424571990967
get_batch_contrastive_loss time: 0.9673318862915039
passed train_by_single_batch
0.0004
batch_time: 2.7441723346710205
get_batch_contrastive_loss time: 0.9770433902740479
passed train_by_single_batch

  0%|                                                                                                                                                                                                                                                | 4/9000 [00:23<12:28:35,  4.99s/it]
batch_time: 2.6948604583740234
get_batch_contrastive_loss time: 0.9450209140777588
passed train_by_single_batch

  0%|▏                                                                                                                                                                                                                                               | 5/9000 [00:27<11:23:59,  4.56s/it]
batch_time: 2.7203831672668457
get_batch_contrastive_loss time: 0.9750945568084717
passed train_by_single_batch

  0%|▏                                                                                                                                                                                                                                               | 6/9000 [00:31<10:47:46,  4.32s/it]

  0%|▏                                                                                                                                                                                                                                               | 7/9000 [00:35<10:24:04,  4.16s/it]
get_batch_contrastive_loss time: 0.9645652770996094
passed train_by_single_batch
0.0004

  0%|▏                                                                                                                                                                                                                                               | 8/9000 [00:39<10:06:48,  4.05s/it]
get_batch_contrastive_loss time: 0.9669222831726074
passed train_by_single_batch
0.0004
batch_time: 2.7233660221099854
get_batch_contrastive_loss time: 0.9410843849182129
passed train_by_single_batch
  0%|▏                                                                                                                                                                                                                                               | 9/9000 [00:44<12:15:46,  4.91s/it]
Traceback (most recent call last):
  File "emb_train.py", line 169, in <module>
    trainer.train_by_num_epoch(args.num_epochs)
  File "/home/clay/userdata/title_generation/emb_trainer.py", line 80, in train_by_num_epoch
    for batch in self.train_loader:
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/clay/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 290, in __getitem__
    return self.dataset[self.indices[idx]]
  File "/home/clay/userdata/title_generation/emb_data_utils.py", line 595, in __getitem__
    token_2 = self.encode_m_offset(token[2], new_header)
  File "/home/clay/userdata/title_generation/emb_data_utils.py", line 635, in encode_m_offset
    numer, denom, is_compound, is_triple = self.parse_meter(meter)
  File "/home/clay/userdata/title_generation/emb_data_utils.py", line 680, in parse_meter
    numer, denom = meter.split('/')
KeyboardInterrupt